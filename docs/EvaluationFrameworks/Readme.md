# Evaluation Frameworks

## LLM Evaluation Frameworks

- [Confident AI DeepEval](https://docs.confident-ai.com/): the open-source LLM evaluation framework

## AI Agents Evaluation

- [Meta - MLGym: A Framework & Benchmark for Advancing AI Research Agents](https://arxiv.org/abs/2502.14499), [GitHub](https://github.com/facebookresearch/MLGym)